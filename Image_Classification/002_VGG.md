### VGG 

- 网络亮点

  - 通过堆叠多个 3x3 的卷积核来代替更大尺寸的卷积核，从而减少模型的参数

  > 通过叠加两个 3x3 的卷积核可以替代一个 5x5 的卷积核，通过叠加三个 3x3 的卷积核可以替代一个 7x7 的卷积核

- 感受野

  - 定义：某一层的输出结果中的一个元素对应于输入层的区域大小，即 feature map 上的一个单元对应于输入层的区域大小

  - 符号说明：$F_i$ 表示第 $i$ 层的感受野，stride 表示第 $i$ 层的步距大小，$K_{size}$ 表示卷积核或者池化核的大小

  - 公式表示
    $$
    F_i = (F_{i+1}-1) \times stride + K_{size}
    $$

  - 示例：一个输入经过一个 pool (size:2, stride:2) 和一个 conv (size:3, stride:2) 对应的感受野大小
    $$
    Feature\ map: 1 \\
        Pool : F = (1 - 1) \times 2 + 2 = 2 \\
        Conv : F = (2 - 1) \times 2 + 3 = 2 + 3 = 5
    $$

- 网络架构

  - 网络结构说明：
    - A, B, C, D, E 表示 5 中不同层数的网络结构
    - A 与 A-LRN 相同层网络，区别在于有无局部响应归一化
    - 模型流程 【以 16 层 D 为例】
      - 模型输入大小 [$224 \times 224$]
      - 两层卷积核大小为 3，填充为 1，卷积核个数为 64 [$224 \times 224 \rightarrow 224 \times 224$]
      - 池化核大小为 2，步距为 2 [$224 \times 224 \rightarrow 112\times 112$]
      - 两层卷积核大小为 3，填充为 1，卷积核个数为 128 [$112\times 112 \rightarrow 112\times 112$]
      - 池化核大小为 2，步距为 2 [$112\times 112\rightarrow 56\times 56$]
      - 三层卷积核大小为 3，填充为 1，卷积核个数为 256[$56\times 56\rightarrow 56\times 56$]
      - 池化核大小为 2，步距为 2 [$56\times 56\rightarrow 28\times 28$]
      - 三层卷积核大小为 3，填充为 1，卷积核个数为 512[$28\times 28\rightarrow 28\times 28$]
      - 池化核大小为 2，步距为 2 [$28 \times 28\rightarrow 14\times 14$]
      - 三层卷积核大小为 3，填充为 1，卷积核个数为 512[$14\times 14\rightarrow 14\times 14$]
      - 池化核大小为 2，步距为 2 [$14\times 14\rightarrow 7\times 7$]
      - 全连接层，神经元个数为 4096 [$512\times 7 \times 7 \rightarrow 4096$]
      - 全连接层，神经元个数为 4096 [$4096 \rightarrow 4096$]
      - 全连接层，神经元个数为 1000 [$4096 \rightarrow 1000$]

  ![VGG 不同层级结构](https://cdn.jsdelivr.net/gh/cjl960828/Deep_Learning_Task/Image_Classification/img/VGG.png)

- pytorch 版本的 VGG 网络搭建

  ```python
  import torch.nn as nn
  import torch
  
  # 预训练模型下载网址
  model_urls = {
      'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',
      'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',
      'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',
      'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth'
  }
  
  
  class VGG(nn.Module):
      def __init__(self, features, num_classes=1000, init_weights=False):
          super(VGG, self).__init__()
          # [224 224 3] -> [7 7 512]
          self.features = features
          self.classifier = nn.Sequential(
              # input 512 * 7 * 7  output 4096
              nn.Linear(512*7*7, 4096),
              nn.ReLU(True),
              nn.Dropout(p=0.5),
              # input 4096  output 4096
              nn.Linear(4096, 4096),
              nn.ReLU(True),
              nn.Dropout(p=0.5),
              # input 4096  output num_classes
              nn.Linear(4096, num_classes)
          )
          if init_weights:
              self._initialize_weights()
  
      def forward(self, x):
          # N x 3 x 224 x 224
          x = self.features(x)
          # N x 512 x 7 x 7
          x = torch.flatten(x, start_dim=1)
          # N x 512*7*7
          x = self.classifier(x)
          return x
  
      def _initialize_weights(self):
          for m in self.modules():
              if isinstance(m, nn.Conv2d):
                  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                  nn.init.xavier_uniform_(m.weight)
                  if m.bias is not None:
                      nn.init.constant_(m.bias, 0)
              elif isinstance(m, nn.Linear):
                  nn.init.xavier_uniform_(m.weight)
                  # nn.init.normal_(m.weight, 0, 0.01)
                  nn.init.constant_(m.bias, 0)
  
  
  def make_features(cfg: list):
      layers = []
      in_channels = 3
      # 逐步读取进行搭建
      for v in cfg:
          if v == "M":
              layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
          else:
              conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
              layers += [conv2d, nn.ReLU(True)]
              in_channels = v
      return nn.Sequential(*layers)
  
  # A B D E
  cfgs = {
      'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
      'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
      'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],
      'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],
  }
  
  
  def vgg(model_name="vgg16", **kwargs):
      assert model_name in cfgs, "Warning: model number {} not in cfgs dict!".format(model_name)
      cfg = cfgs[model_name]
  
      model = VGG(make_features(cfg), **kwargs)
      return model
  
  ```

- tensorflow2 版本的 VGG 网络搭建

  ```python
  from tensorflow.keras import layers, Model, Sequential
  
  CONV_KERNEL_INITIALIZER = {
      'class_name': 'VarianceScaling',
      'config': {
          'scale': 2.0,
          'mode': 'fan_out',
          'distribution': 'truncated_normal'
      }
  }
  
  DENSE_KERNEL_INITIALIZER = {
      'class_name': 'VarianceScaling',
      'config': {
          'scale': 1. / 3.,
          'mode': 'fan_out',
          'distribution': 'uniform'
      }
  }
  
  
  def VGG(feature, im_height=224, im_width=224, num_classes=1000):
      # tensorflow 中的 tensor 通道排序是 NHWC
      input_image = layers.Input(shape=(im_height, im_width, 3), dtype="float32")
      x = feature(input_image)
      x = layers.Flatten()(x)
      x = layers.Dropout(rate=0.5)(x)
      x = layers.Dense(4096, activation='relu',
                       kernel_initializer=DENSE_KERNEL_INITIALIZER)(x)
      x = layers.Dropout(rate=0.5)(x)
      x = layers.Dense(4096, activation='relu',
                       kernel_initializer=DENSE_KERNEL_INITIALIZER)(x)
      x = layers.Dense(num_classes,
                       kernel_initializer=DENSE_KERNEL_INITIALIZER)(x)
      output = layers.Softmax()(x)
      model = Model(inputs=input_image, outputs=output)
      return model
  
  
  def make_feature(cfg):
      feature_layers = []
      for v in cfg:
          if v == "M":
              feature_layers.append(layers.MaxPool2D(pool_size=2, strides=2))
          else:
              conv2d = layers.Conv2D(v, kernel_size=3, padding="SAME", activation="relu",
                                     kernel_initializer=CONV_KERNEL_INITIALIZER)
              feature_layers.append(conv2d)
      return Sequential(feature_layers, name="feature")
  
  # A B D E
  cfgs = {
      'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
      'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
      'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],
      'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],
  }
  
  
  def vgg(model_name="vgg16", im_height=224, im_width=224, num_classes=1000):
      assert model_name in cfgs.keys(), "not support model {}".format(model_name)
      cfg = cfgs[model_name]
      model = VGG(make_feature(cfg), im_height=im_height, im_width=im_width, num_classes=num_classes)
      return model
  
  ```

  